#!/usr/bin/env python3
"""
Test script to verify compatibility with actual Gahan AI dataset.
Tests XML parsing, ROI filtering, and data loading pipeline.
"""

import os
import sys
import torch
import xml.etree.ElementTree as ET
from pathlib import Path
import cv2
import numpy as np

# Add project root to path
sys.path.append('.')

from datasets.cut_in_dataset import CutInSequenceDataset
from utils.roi_ops import filter_objects_by_roi, normalize_bbox
from models.cutting_detector import create_cutting_detector
import yaml

def test_xml_parsing():
    """Test XML parsing with the actual data format."""
    print("üîç Testing XML Parsing...")
    
    # Sample XML content from user's data
    xml_content = '''<annotation>
<folder>frame</folder>
<filename>frame_000000.PNG</filename>
<source>
<database>Unknown</database>
<annotation>Unknown</annotation>
<image>Unknown</image>
</source>
<size>
<width>1920</width>
<height>1080</height>
<depth/>
</size>
<segmented>0</segmented>
<object>
<name>EgoVehicle</name>
<occluded>0</occluded>
<bndbox>
<xmin>2.39</xmin>
<ymin>867.19</ymin>
<xmax>1920.0</xmax>
<ymax>1080.0</ymax>
<x-axis>1269764.35</x-axis>
<y-axis>5948261.09</y-axis>
<z-axis>1931159.28</z-axis>
</bndbox>
<attributes>
<attribute>
<name>Cutting</name>
<value>False</value>
</attribute>
</attributes>
</object>
<object>
<name>MotorBike</name>
<occluded>0</occluded>
<bndbox>
<xmin>858.57</xmin>
<ymin>728.3</ymin>
<xmax>900.93</xmax>
<ymax>800.2</ymax>
</bndbox>
<attributes>
<attribute>
<name>Cutting</name>
<value>False</value>
</attribute>
</attributes>
</object>
<object>
<name>Car</name>
<occluded>0</occluded>
<bndbox>
<xmin>955.6</xmin>
<ymin>738.6</ymin>
<xmax>1041.8</xmax>
<ymax>816.26</ymax>
</bndbox>
<attributes>
<attribute>
<name>Cutting</name>
<value>False</value>
</attribute>
</attributes>
</object>
</annotation>'''
    
    # Parse XML
    root = ET.fromstring(xml_content)
    
    # Get image size
    size_elem = root.find('size')
    width = int(size_elem.find('width').text)
    height = int(size_elem.find('height').text)
    image_size = (width, height)
    
    print(f"‚úÖ Image size: {image_size}")
    
    # Parse objects
    objects = []
    class_to_idx = {'Background': 0, 'Car': 1, 'MotorBike': 2, 'EgoVehicle': 3}
    
    for obj in root.findall('object'):
        name = obj.find('name').text
        if name not in class_to_idx:
            continue
        
        bbox = obj.find('bndbox')
        x1 = float(bbox.find('xmin').text)
        y1 = float(bbox.find('ymin').text)
        x2 = float(bbox.find('xmax').text)
        y2 = float(bbox.find('ymax').text)
        
        # Get cutting attribute
        cutting = False
        cutting_elem = obj.find('attributes/attribute[name="Cutting"]')
        if cutting_elem is not None:
            cutting_value = cutting_elem.find('value')
            if cutting_value is not None:
                cutting = cutting_value.text.lower() == 'true'
        
        obj_data = {
            'class': name,
            'class_id': class_to_idx[name],
            'bbox': [x1, y1, x2, y2],
            'cutting': cutting
        }
        
        objects.append(obj_data)
    
    print(f"‚úÖ Parsed {len(objects)} objects:")
    for obj in objects:
        print(f"   - {obj['class']}: bbox={obj['bbox']}, cutting={obj['cutting']}")
    
    return objects, image_size

def test_roi_filtering(objects, image_size):
    """Test ROI filtering with actual data."""
    print("\nüéØ Testing ROI Filtering...")
    
    roi_bounds = [480, 540, 1440, 1080]  # Our optimized ROI
    
    print(f"ROI bounds: {roi_bounds}")
    print(f"Image size: {image_size}")
    
    # Filter objects by ROI
    filtered_objects = filter_objects_by_roi(objects, roi_bounds, image_size)
    
    print(f"‚úÖ Objects before ROI filtering: {len(objects)}")
    print(f"‚úÖ Objects after ROI filtering: {len(filtered_objects)}")
    
    for obj in filtered_objects:
        center_x = (obj['bbox'][0] + obj['bbox'][2]) / 2
        center_y = (obj['bbox'][1] + obj['bbox'][3]) / 2
        print(f"   - {obj['class']}: center=({center_x:.1f}, {center_y:.1f})")
    
    return filtered_objects

def test_bbox_normalization(objects, image_size):
    """Test bounding box normalization."""
    print("\nüìè Testing Bbox Normalization...")
    
    for obj in objects:
        original_bbox = obj['bbox']
        normalized_bbox = normalize_bbox(original_bbox, image_size)
        
        print(f"‚úÖ {obj['class']}:")
        print(f"   Original: {original_bbox}")
        print(f"   Normalized: {[f'{x:.3f}' for x in normalized_bbox]}")

def test_model_compatibility():
    """Test model creation and forward pass."""
    print("\nü§ñ Testing Model Compatibility...")
    
    # Load config
    with open('configs/experiment_config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # Create model
    model = create_cutting_detector(config['model'])
    model.eval()
    
    print(f"‚úÖ Model created successfully")
    print(f"   - Parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # Test forward pass
    batch_size = 2
    seq_len = 5
    channels = 3
    height = 224  # ViT input size
    width = 224
    
    dummy_images = torch.randn(batch_size, seq_len, channels, height, width)
    
    with torch.no_grad():
        outputs = model(dummy_images)
    
    print(f"‚úÖ Forward pass successful")
    print(f"   - Output keys: {list(outputs.keys())}")
    print(f"   - Pred logits shape: {outputs['pred_logits'].shape}")
    print(f"   - Pred boxes shape: {outputs['pred_boxes'].shape}")
    print(f"   - Pred cutting shape: {outputs['pred_cutting'].shape}")

def test_dataset_structure():
    """Test expected dataset directory structure."""
    print("\nüìÅ Testing Dataset Structure...")
    
    expected_paths = [
        "gahan-ai-dataset-extracted/dataset/dataset/distribution/Train",
        "gahan-ai-dataset-extracted/dataset/dataset/distribution/Test"
    ]
    
    for path in expected_paths:
        if os.path.exists(path):
            print(f"‚úÖ Found: {path}")
            
            # List subdirectories
            subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]
            print(f"   Subdirectories: {len(subdirs)}")
            
            if subdirs:
                sample_dir = os.path.join(path, subdirs[0])
                if os.path.exists(os.path.join(sample_dir, "Annotations")):
                    print(f"   ‚úÖ Annotations folder found")
                if os.path.exists(os.path.join(sample_dir, "Images")):
                    print(f"   ‚úÖ Images folder found")
        else:
            print(f"‚ùå Not found: {path}")

def main():
    """Run all compatibility tests."""
    print("üöÄ Gahan AI Dataset Compatibility Test")
    print("=" * 50)
    
    try:
        # Test XML parsing
        objects, image_size = test_xml_parsing()
        
        # Test ROI filtering
        filtered_objects = test_roi_filtering(objects, image_size)
        
        # Test bbox normalization
        test_bbox_normalization(filtered_objects, image_size)
        
        # Test model compatibility
        test_model_compatibility()
        
        # Test dataset structure
        test_dataset_structure()
        
        print("\n" + "=" * 50)
        print("üéâ ALL TESTS PASSED!")
        print("‚úÖ Your dataset is 100% compatible with our system!")
        print("‚úÖ Ready to start training for F1 > 0.85!")
        
    except Exception as e:
        print(f"\n‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 